# File: Write.py
# Purpose: Main orchestrator for the AI Story Writer application.

"""
AI Story Writer - Main Orchestration Script.

This script drives the entire story generation process, from taking a user's
initial prompt to producing a complete, multi-chapter narrative.
It initializes components, manages workflow (outline, chapters, scenes),
handles optional processing (editing, scrubbing, translation), extracts
metadata, and saves all outputs.
"""

import argparse
import time
import datetime
import os
import json
import sys
import re
from typing import List, Optional, Dict, Any, Tuple, Union

# Ensure the Writer package is discoverable.
try:
    import Writer.Config as Config
    import Writer.Interface.Wrapper as Wrapper
    import Writer.PrintUtils as PrintUtils
    import Writer.Chapter.ChapterDetector as ChapterDetector
    import Writer.Scrubber as Scrubber
    import Writer.Statistics as Statistics
    import Writer.OutlineGenerator as OutlineGenerator
    import Writer.Chapter.ChapterGenerator as ChapterGenerator
    import Writer.Chapter.ChapterContext as ChapterContext
    import Writer.StoryInfo as StoryInfo
    import Writer.NovelEditor as NovelEditor
    import Writer.Translator as Translator
    import Writer.Prompts as Prompts
    import Writer.Scene.SceneOutliner as SceneOutliner
except ImportError as e:
    current_dir = os.path.dirname(os.path.abspath(__file__))
    project_root = current_dir
    if "AIStoryWriter" in project_root.split(os.sep)[-1] and "Writer" not in os.listdir(
        project_root
    ):
        project_root = os.path.dirname(project_root)

    if project_root not in sys.path:
        sys.path.insert(0, project_root)
    try:
        import Writer.Config as Config
        import Writer.Interface.Wrapper as Wrapper
        import Writer.PrintUtils as PrintUtils
        import Writer.Chapter.ChapterDetector as ChapterDetector
        import Writer.Scrubber as Scrubber
        import Writer.Statistics as Statistics
        import Writer.OutlineGenerator as OutlineGenerator
        import Writer.Chapter.ChapterGenerator as ChapterGenerator
        import Writer.Chapter.ChapterContext as ChapterContext
        import Writer.StoryInfo as StoryInfo
        import Writer.NovelEditor as NovelEditor
        import Writer.Translator as Translator
        import Writer.Prompts as Prompts
        import Writer.Scene.SceneOutliner as SceneOutliner
    except ImportError:
        print(
            f"CRITICAL ERROR: Failed to import necessary Writer modules. Original error: {e}"
        )
        print(
            "Ensure AIStoryWriter modules are in PYTHONPATH or script is run from project root."
        )
        print(f"Current sys.path: {sys.path}")
        sys.exit(1)


def parse_arguments() -> argparse.Namespace:
    """Parses command-line arguments for the story generation script."""
    parser = argparse.ArgumentParser(
        description="AI Story Writer: Generates a multi-chapter narrative."
    )
    # Core Inputs/Outputs
    parser.add_argument(
        "-Prompt",
        required=True,
        help="Path to a text file containing the user's story prompt.",
    )
    parser.add_argument(
        "-Output",
        default="",
        type=str,
        help="Optional base filename for output (e.g., 'MyStory'). "
        "If empty, autogenerated from title.",
    )

    # Model Configuration
    parser.add_argument(
        "-InitialOutlineModel",
        default=Config.INITIAL_OUTLINE_WRITER_MODEL,
        type=str,
        help="Model for the main story outline.",
    )
    parser.add_argument(
        "-ModelStoryElementsGenerator",
        default=Config.MODEL_STORY_ELEMENTS_GENERATOR,
        type=str,
        help="Model for story elements (genre, theme, etc.).",
    )
    parser.add_argument(
        "-ModelSceneOutliner",
        default=Config.MODEL_SCENE_OUTLINER,
        type=str,
        help="Model for breaking chapters into scene outlines.",
    )
    parser.add_argument(
        "-ModelSceneNarrativeGenerator",
        default=Config.MODEL_SCENE_NARRATIVE_GENERATOR,
        type=str,
        help="Model for writing individual scene narratives.",
    )
    parser.add_argument(
        "-ModelChapterContextSummarizer",
        default=Config.MODEL_CHAPTER_CONTEXT_SUMMARIZER,
        type=str,
        help="Model for summarizing chapter/scene context.",
    )
    parser.add_argument(
        "-ModelChapterAssemblyRefiner",
        default=Config.MODEL_CHAPTER_ASSEMBLY_REFINER,
        type=str,
        help="Model for refining assembled scenes into a cohesive chapter.",
    )
    parser.add_argument(
        "-ChapterRevisionModel",
        default=Config.CHAPTER_REVISION_WRITER_MODEL,
        type=str,
        help="Model for revising chapters based on LLM feedback.",
    )
    parser.add_argument(
        "-RevisionModel",
        default=Config.REVISION_MODEL,
        type=str,
        help="Model for generating critique/feedback.",
    )
    parser.add_argument(
        "-EvalModel",
        default=Config.EVAL_MODEL,
        type=str,
        help="Model for evaluation tasks (e.g., ratings, JSON checks).",
    )
    parser.add_argument(
        "-InfoModel",
        default=Config.INFO_MODEL,
        type=str,
        help="Model for extracting story metadata (title, summary, tags).",
    )
    parser.add_argument(
        "-ScrubModel",
        default=Config.SCRUB_MODEL,
        type=str,
        help="Model for cleaning final text.",
    )
    parser.add_argument(
        "-CheckerModel",
        default=Config.CHECKER_MODEL,
        type=str,
        help="Model for simple validation/parsing aid (e.g., chapter count).",
    )
    parser.add_argument(
        "-TranslatorModel",
        default=Config.TRANSLATOR_MODEL,
        type=str,
        help="Model for translation tasks.",
    )

    # Generation Parameters
    parser.add_argument(
        "-Seed",
        default=Config.SEED,
        type=int,
        help="Seed for LLM generation (for reproducibility).",
    )
    parser.add_argument(
        "-Translate",
        default=Config.TRANSLATE_LANGUAGE,
        type=str,
        help="Target language for story translation (e.g., 'French'). Leave empty for no translation.",
    )
    parser.add_argument(
        "-TranslatePrompt",
        default=Config.TRANSLATE_PROMPT_LANGUAGE,
        type=str,
        help="Target language for user prompt translation (e.g., 'English' if prompt is non-English).",
    )

    # Revision Control
    parser.add_argument(
        "-OutlineMinRevisions",
        default=Config.OUTLINE_MIN_REVISIONS,
        type=int,
        help="Minimum revision cycles for the main outline.",
    )
    parser.add_argument(
        "-OutlineMaxRevisions",
        default=Config.OUTLINE_MAX_REVISIONS,
        type=int,
        help="Maximum revision cycles for the main outline.",
    )
    parser.add_argument(
        "-ChapterMinRevisions",
        default=Config.CHAPTER_MIN_REVISIONS,
        type=int,
        help="Minimum revision cycles for an assembled chapter.",
    )
    parser.add_argument(
        "-ChapterMaxRevisions",
        default=Config.CHAPTER_MAX_REVISIONS,
        type=int,
        help="Maximum revision cycles for an assembled chapter.",
    )
    parser.add_argument(
        "-NoChapterRevision",
        action="store_true",
        help="Disables feedback/revision loops for assembled chapters. Overrides Config default if present.",
    )

    # Feature Flags
    parser.add_argument(
        "-NoScrubChapters",
        action="store_true",
        help="Disables the final scrubbing pass on chapters. Overrides Config default if present.",
    )
    parser.add_argument(
        "-EnableFinalEditPass",
        action="store_true",
        help="Enables a global novel editing pass. Overrides Config default if present.",
    )

    # Debugging
    parser.add_argument(
        "-Debug",
        action="store_true",
        help="Enables verbose debugging output. Overrides Config default if present.",
    )
    parser.add_argument(
        "-DebugLevel",
        default=Config.DEBUG_LEVEL,
        type=int,
        help="Sets debug verbosity (0=off, 1=basic, 2=detailed: includes stream chunks).",
    )
    return parser.parse_args()


def apply_config_from_args(args: argparse.Namespace, logger: PrintUtils.Logger) -> None:
    """Applies parsed command-line arguments to the global Config module."""
    logger.Log("Applying command-line arguments to configuration...", 0)
    for arg_name, arg_value in vars(args).items():
        config_attr_name = arg_name.upper()
        # Handle special flag cases
        if arg_name == "NoChapterRevision":
            Config.CHAPTER_NO_REVISIONS = arg_value
        elif arg_name == "NoScrubChapters":
            Config.SCRUB_NO_SCRUB = arg_value
        elif arg_name == "EnableFinalEditPass":
            Config.ENABLE_FINAL_EDIT_PASS = arg_value
        elif arg_name == "Debug":
            Config.DEBUG = arg_value
        # For all other args, map directly to Config attributes
        elif hasattr(Config, config_attr_name):
            current_config_val = getattr(Config, config_attr_name)
            if current_config_val != arg_value:
                logger.Log(f"Config: '{config_attr_name}' changing from '{current_config_val}' to '{arg_value}'.", 0)
            setattr(Config, config_attr_name, arg_value)
    
    Config.SCENE_GENERATION_PIPELINE = True # This is the primary mode of operation now
    logger.Log("Configuration updated from command-line arguments.", 0)


def load_user_prompt_file(
    prompt_filepath: str, logger: PrintUtils.Logger
) -> Optional[str]:
    """Loads content from the user's prompt file, with error handling."""
    logger.Log(f"Loading user prompt from: {prompt_filepath}", 1)
    if not os.path.exists(prompt_filepath):
        logger.Log(f"Error: Prompt file not found at '{prompt_filepath}'.", 7)
        return None
    try:
        with open(prompt_filepath, "r", encoding="utf-8") as f:
            prompt_text = f.read()
        if not prompt_text.strip():
            logger.Log(f"Warning: Prompt file '{prompt_filepath}' is empty.", 6)
            return ""
        logger.Log("User prompt loaded successfully.", 1)
        return prompt_text
    except IOError as e:
        logger.Log(f"Error reading prompt file '{prompt_filepath}': {e}", 7)
        return None
    except Exception as e:
        logger.Log(f"Unexpected error reading prompt file '{prompt_filepath}': {e}", 7)
        return None


def split_overall_outline_into_chapter_plots(
    overall_chapter_level_outline: str,
    num_chapters: int,
    interface: Wrapper.Interface,
    logger: PrintUtils.Logger,
) -> List[str]:
    """
    Splits a comprehensive chapter-level outline into individual plot strings for each chapter.
    Uses regex first, then falls back to LLM-based segmentation if regex is inconclusive.
    """
    logger.Log(
        f"Segmenting overall outline into {num_chapters} chapter-specific plot outlines...",
        3,
    )
    pattern = re.compile(
        r"(?:Chapter\s*\d+\s*:?|\#{1,3}\s*Chapter\s*\d+\s*:?)[^\n]*\n(.*?)(?=\n(?:Chapter\s*\d+\s*:?|\#{1,3}\s*Chapter\s*\d+\s*:?)|\Z)",
        re.IGNORECASE | re.DOTALL,
    )
    parsed_plots_via_find = [
        match.strip() for match in pattern.findall(overall_chapter_level_outline)
    ]

    if len(parsed_plots_via_find) == num_chapters:
        logger.Log(
            f"Successfully segmented outline into {num_chapters} chapter plots using regex findall.",
            4,
        )
        return parsed_plots_via_find

    logger.Log(
        f"Regex findall yielded {len(parsed_plots_via_find)} plots, expected {num_chapters}. Using LLM or broader regex split.",
        5,
    )
    chapter_segments = re.split(
        r"\n(?:Chapter\s*\d+\s*:?|\#{1,3}\s*Chapter\s*\d+\s*:?)[^\n]*\n",
        overall_chapter_level_outline,
        flags=re.IGNORECASE,
    )
    parsed_plots_via_split = [seg.strip() for seg in chapter_segments if seg.strip()]

    if parsed_plots_via_split and (
        not parsed_plots_via_split[0]
        or parsed_plots_via_split[0].lower().startswith(("introduction", "prologue"))
    ):
        if len(parsed_plots_via_split) - 1 == num_chapters:
            logger.Log("Adjusted regex split by removing initial segment.", 5)
            parsed_plots_via_split = parsed_plots_via_split[1:]

    if len(parsed_plots_via_split) == num_chapters:
        logger.Log(
            f"Successfully segmented outline into {num_chapters} chapter plots using regex split.",
            4,
        )
        return parsed_plots_via_split

    logger.Log(
        f"Regex split yielded {len(parsed_plots_via_split)} plots. Attempting LLM-based segmentation.",
        5,
    )
    prompt_text = (
        f"The following is a story outline that describes {num_chapters} chapters.\n"
        f"Please divide this outline into {num_chapters} distinct sections, where each section\n"
        f"corresponds to the plot summary or key events for one chapter.\n"
        f"Present your output as a JSON list of strings, where each string is the plot content for one chapter.\n"
        f"Ensure there are exactly {num_chapters} strings in the list. If the outline seems to have more or fewer logical chapter divisions than {num_chapters},\n"
        f"do your best to consolidate or expand to meet the {num_chapters} target, prioritizing the main plot points.\n\n"
        f"Original Outline:\n---\n{overall_chapter_level_outline}\n---\n\n"
        f"JSON List of Chapter Plot Strings (exactly {num_chapters} items):"
    )
    messages = [
        interface.build_system_query(
            "You are an AI assistant that accurately segments text into a specified number of chapter summaries and formats them as a JSON list."
        ),
        interface.build_user_query(prompt_text),
    ]
    try:
        _response_msgs, parsed_json_list = interface.safe_generate_json(
            logger, messages, Config.CHECKER_MODEL, required_attribs=[]
        )
        if isinstance(parsed_json_list, list) and all(
            isinstance(item, str) for item in parsed_json_list
        ):
            if len(parsed_json_list) == num_chapters:
                logger.Log(
                    f"LLM successfully segmented outline into {len(parsed_json_list)} chapter plots.",
                    4,
                )
                return parsed_json_list
            logger.Log(
                f"LLM segmentation returned {len(parsed_json_list)} plots, but {num_chapters} were expected. Adjusting list or using fallback.",
                6,
            )
            if len(parsed_json_list) > num_chapters:
                return parsed_json_list[:num_chapters]
            if len(parsed_json_list) < num_chapters and parsed_json_list:
                return parsed_json_list + [
                    "Plot segment for this chapter was not clearly delineated by LLM."
                ] * (num_chapters - len(parsed_json_list))
        else:
            logger.Log(
                f"LLM segmentation did not return a JSON list of strings. Type: {type(parsed_json_list)}. Using prior regex or crude split.",
                6,
            )
    except Exception as e:
        logger.Log(
            f"Error during LLM-based outline segmentation: {e}. Using prior regex or crude split.",
            6,
        )
    best_regex_plots = (
        parsed_plots_via_find
        if len(parsed_plots_via_find) > len(parsed_plots_via_split)
        else parsed_plots_via_split
    )
    if best_regex_plots and (len(best_regex_plots) >= num_chapters * 0.5):
        logger.Log(
            f"Falling back to best regex-parsed plots ({len(best_regex_plots)} found) due to LLM segmentation issues.",
            6,
        )
        if len(best_regex_plots) > num_chapters:
            return best_regex_plots[:num_chapters]
        return best_regex_plots + [
            "Plot segment missing or could not be parsed by regex."
        ] * (num_chapters - len(best_regex_plots))
    logger.Log(
        "All segmentation methods had issues. Performing a crude split. Chapter plot quality may be low.",
        7,
    )
    avg_len = (
        len(overall_chapter_level_outline) // num_chapters
        if num_chapters > 0
        else len(overall_chapter_level_outline)
    )
    if avg_len == 0 and num_chapters > 0:
        return ["Error: Crude split resulted in empty segment."] * num_chapters
    return [
        overall_chapter_level_outline[i * avg_len : (i + 1) * avg_len].strip()
        or f"Segment {i+1} empty after crude split."
        for i in range(num_chapters)
    ]


def _generate_fallback_plot_string_for_chapter(
    interface: Wrapper.Interface,
    logger: PrintUtils.Logger,
    chapter_num: int,
    total_chapters: int,
    overall_story_outline: str,
    base_story_context: Optional[str],
) -> str:
    """Generates a fallback plot string for a chapter if its segment is problematic."""
    logger.Log(f"Generating fallback plot string for Chapter {chapter_num}...", 5)
    try:
        prompt_template = Prompts.FALLBACK_CHAPTER_PLOT_GENERATION_PROMPT
        formatted_prompt = prompt_template.format(
            ChapterNum=chapter_num,
            TotalChapters=total_chapters,
            OverallStoryOutline=overall_story_outline,
            BaseStoryContext=(
                base_story_context if base_story_context else "Not provided."
            ),
        )
    except AttributeError:  # Check if prompt is defined in Prompts module
        logger.Log(
            "FALLBACK_CHAPTER_PLOT_GENERATION_PROMPT not found in Prompts.py!", 7
        )
        return f"Error: Fallback prompt missing. Chapter {chapter_num} plot cannot be generated."
    except KeyError as e:
        logger.Log(
            f"Fallback plot prompt formatting error for Chapter {chapter_num}: {e}", 7
        )
        return f"Error: Fallback prompt key error. Chapter {chapter_num} plot error."

    messages = [
        interface.build_system_query(
            "You are an AI story assistant helping to create a coherent plot for a chapter whose specific details are missing."
        ),
        interface.build_user_query(formatted_prompt),
    ]
    try:
        response_messages = interface.safe_generate_text(
            logger, messages, Config.MODEL_SCENE_OUTLINER, min_word_count=20
        )
        fallback_plot = interface.get_last_message_text(response_messages)
        if not fallback_plot.strip() or "Error:" in fallback_plot:
            logger.Log(
                f"LLM failed to generate fallback plot for Chapter {chapter_num}.", 6
            )
            return f"Error: LLM failed to generate fallback plot for Chapter {chapter_num}."
        logger.Log(
            f"Fallback plot generated for Chapter {chapter_num}: '{fallback_plot[:100]}...'",
            4,
        )
        return fallback_plot
    except Exception as e:
        logger.Log(
            f"Exception generating fallback plot for Chapter {chapter_num}: {e}", 7
        )
        return f"Error: Exception during fallback plot generation for Chapter {chapter_num}."


def _log_generated_scenes_to_plot_file(
    logger: PrintUtils.Logger,
    scene_outlines: List[Dict[str, Any]],
    plot_segment_filepath: str,
) -> None:
    """Appends formatted scene outlines to the chapter's plot segment log file."""
    if not scene_outlines:
        return
    logger.Log(
        f"Appending {len(scene_outlines)} generated scene outlines to {os.path.basename(plot_segment_filepath)}",
        3,
    )
    try:
        with open(plot_segment_filepath, "a", encoding="utf-8") as f_plot_log:
            f_plot_log.write(
                "\n\n--- GENERATED SCENE OUTLINES FOR THIS CHAPTER SEGMENT ---\n"
            )
            for idx, scene_dict in enumerate(scene_outlines):
                scene_num_in_chapter = scene_dict.get(
                    "scene_number_in_chapter", idx + 1
                )
                title = scene_dict.get("scene_title", "Untitled Scene")
                setting = scene_dict.get("setting_description", "N/A")
                events = scene_dict.get("key_events_actions", ["N/A"])
                events_str = (
                    "; ".join(map(str, events)) if isinstance(events, list) else str(events)
                )

                f_plot_log.write(
                    f"{scene_num_in_chapter}. **{title}**\n"
                    f"   Setting: {setting}\n"
                    f"   Events: {events_str}\n"
                    f"   Purpose: {scene_dict.get('purpose_in_chapter', 'N/A')}\n\n"
                )
            f_plot_log.write("--- END GENERATED SCENE OUTLINES ---\n")
    except IOError as e:
        logger.Log(f"Error appending scene outlines to {plot_segment_filepath}: {e}", 7)
    except Exception as e:
        logger.Log(
            f"Unexpected error appending scene outlines to {plot_segment_filepath}: {e}",
            7,
        )


def main() -> None:
    """Main function to orchestrate the story generation process."""
    args = parse_arguments()
    logger = PrintUtils.Logger(log_dir_base="Logs")
    logger.Log("AIStoryWriter Refactored - Initialization Started.", 0)
    apply_config_from_args(args, logger)
    start_time_total = time.time()

    models_to_load = list(set([
        Config.INITIAL_OUTLINE_WRITER_MODEL, Config.MODEL_STORY_ELEMENTS_GENERATOR,
        Config.MODEL_SCENE_OUTLINER, Config.MODEL_SCENE_NARRATIVE_GENERATOR,
        Config.MODEL_CHAPTER_CONTEXT_SUMMARIZER, Config.MODEL_CHAPTER_ASSEMBLY_REFINER,
        Config.CHAPTER_REVISION_WRITER_MODEL, Config.REVISION_MODEL, Config.EVAL_MODEL,
        Config.INFO_MODEL, Config.SCRUB_MODEL, Config.CHECKER_MODEL, Config.TRANSLATOR_MODEL,
    ]))

    try:
        interface = Wrapper.Interface(logger=logger, models_to_load=models_to_load)
        logger.Log("LLM Interface initialized with specified models.", 1)
    except Exception as e:
        logger.Log(f"CRITICAL: Failed to initialize LLM Interface: {e}. Aborting.", 7)
        logger.close()
        return

    user_prompt_text = load_user_prompt_file(args.Prompt, logger)
    if user_prompt_text is None:
        logger.Log("Exiting due to prompt loading error.", 7)
        logger.close()
        return
    
    original_user_prompt_for_log = user_prompt_text

    if Config.TRANSLATE_PROMPT_LANGUAGE:
        logger.Log(
            f"Translating user prompt to '{Config.TRANSLATE_PROMPT_LANGUAGE}' for LLM processing...",
            1,
        )
        user_prompt_text = Translator.translate_user_prompt(
            interface,
            logger,
            user_prompt_text,
            Config.TRANSLATE_PROMPT_LANGUAGE,
        )
        if "Error:" in user_prompt_text:
            logger.Log(
                f"Prompt translation failed: {user_prompt_text}. Using original prompt.",
                6,
            )
            user_prompt_text = original_user_prompt_for_log

    logger.Log("Phase 1: Generating Story Outline...", 1)
    (
        full_printable_outline, story_elements_md,
        chapter_level_plot_outline, base_story_context_instructions
    ) = OutlineGenerator.generate_outline(interface, logger, user_prompt_text)

    if "Error:" in chapter_level_plot_outline:
        logger.Log(f"Outline generation failed: {chapter_level_plot_outline}. Aborting.", 7)
        logger.save_artifact(full_printable_outline, "Errored_Outline.md")
        logger.close()
        return
    logger.save_artifact(story_elements_md, "1_StoryElements.md")
    logger.save_artifact(chapter_level_plot_outline, "2_ChapterLevelOutline_Raw.md")

    logger.Log("Phase 2: Determining Number of Chapters...", 1)
    num_chapters = ChapterDetector.llm_count_chapters(interface, logger, chapter_level_plot_outline)
    if num_chapters <= 0:
        logger.Log(f"Could not determine a valid number of chapters (detected: {num_chapters}). Aborting.", 7)
        logger.save_artifact(
            full_printable_outline, "3_FullPrintableOutline_PreChapterDetectionError.md"
        )
        logger.close()
        return
    logger.Log(f"Detected {num_chapters} chapters for the story.", 2)

    per_chapter_plot_outlines = split_overall_outline_into_chapter_plots(
        chapter_level_plot_outline, num_chapters, interface, logger
    )
    for i, plot in enumerate(per_chapter_plot_outlines):
        logger.save_artifact(plot, f"2a_Chapter_{i+1}_PlotSegment.txt")

    logger.Log(f"Phase 3: Generating {num_chapters} Chapter(s) Scene-by-Scene...", 1)
    generated_chapters_list: List[str] = []
    previous_chapter_context_summary: Optional[str] = None
    all_generated_scene_outlines_for_json_log: List[List[Dict[str, Any]]] = []

    for i in range(num_chapters):
        current_chapter_num = i + 1
        logger.Log(f"--- Generating Chapter {current_chapter_num}/{num_chapters} ---", 2)
        
        plot_segment_filepath = os.path.join(logger.log_session_dir, f"2a_Chapter_{current_chapter_num}_PlotSegment.txt")
        effective_plot_for_generator = per_chapter_plot_outlines[i]
        if not effective_plot_for_generator.strip() or "Plot segment missing" in effective_plot_for_generator:
            logger.Log(f"Plot for Chapter {current_chapter_num} is problematic. Generating fallback.", 6)
            effective_plot_for_generator = _generate_fallback_plot_string_for_chapter(
                interface, logger, current_chapter_num, num_chapters, chapter_level_plot_outline, base_story_context_instructions
            )

        generated_chapter_text, scene_outlines_used = ChapterGenerator.generate_chapter_by_scenes(
            interface, logger, current_chapter_num, num_chapters, chapter_level_plot_outline,
            effective_plot_for_generator, previous_chapter_context_summary, base_story_context_instructions
        )
        all_generated_scene_outlines_for_json_log.append(scene_outlines_used)
        _log_generated_scenes_to_plot_file(logger, scene_outlines_used, plot_segment_filepath)

        final_formatted_chapter_text = f"## Chapter {current_chapter_num}\n\n{generated_chapter_text}"
        generated_chapters_list.append(final_formatted_chapter_text)
        logger.save_artifact(final_formatted_chapter_text, f"3_Chapter_{current_chapter_num}_Generated.md")

        if "Error:" not in generated_chapter_text and current_chapter_num < num_chapters:
            previous_chapter_context_summary = ChapterContext.generate_previous_chapter_summary(
                interface, logger, generated_chapter_text, chapter_level_plot_outline, current_chapter_num
            )

    # --- Post-generation processing chain ---
    chapters_after_assembly = list(generated_chapters_list)

    # Phase 4: Global Edit (Optional)
    if Config.ENABLE_FINAL_EDIT_PASS:
        logger.Log("Phase 4: Performing Optional Global Novel Editing Pass...", 1)
        globally_edited_chapters = NovelEditor.edit_novel_globally(interface, logger, chapters_after_assembly, chapter_level_plot_outline)
        for i, chap_text in enumerate(globally_edited_chapters):
            logger.save_artifact(chap_text, f"4_Chapter_{i+1}_GloballyEdited.md")
    else:
        logger.Log("Skipping optional global novel editing pass.", 1)
        globally_edited_chapters = list(chapters_after_assembly)

    # Phase 5: Scrubbing (Optional)
    if not Config.SCRUB_NO_SCRUB:
        logger.Log("Phase 5: Scrubbing Final Novel Text...", 1)
        scrubbed_chapters = Scrubber.scrub_novel_chapters(interface, logger, globally_edited_chapters)
        for i, chap_text in enumerate(scrubbed_chapters):
            logger.save_artifact(chap_text, f"5_Chapter_{i+1}_Scrubbed.md")
    else:
        logger.Log("Skipping novel scrubbing pass.", 1)
        scrubbed_chapters = list(globally_edited_chapters)

    # Phase 6: Translation (Optional)
    if Config.TRANSLATE_LANGUAGE:
        logger.Log(f"Phase 6: Translating Novel to '{Config.TRANSLATE_LANGUAGE}'...", 1)
        final_chapters_for_output = Translator.translate_novel_chapters(interface, logger, scrubbed_chapters, Config.TRANSLATE_LANGUAGE)
        for i, chap_text in enumerate(final_chapters_for_output):
            logger.save_artifact(chap_text, f"6_Chapter_{i+1}_Translated_{Config.TRANSLATE_LANGUAGE}.md")
    else:
        logger.Log("Skipping novel translation.", 1)
        final_chapters_for_output = list(scrubbed_chapters)

    final_story_body_text = "\n\n\n".join(final_chapters_for_output)
    logger.save_artifact(final_story_body_text, "7_CompleteStory_Body.md")

    logger.Log("Phase 7: Generating Final Story Metadata...", 1)
    story_metadata = StoryInfo.get_story_info(interface, logger, [interface.build_user_query(full_printable_outline)])

    story_title = story_metadata.get("Title", f"Untitled_Story_{datetime.datetime.now().strftime('%Y%m%d%H%M%S')}")
    story_summary = story_metadata.get("Summary", "Summary not available.")
    story_tags = story_metadata.get("Tags", "No tags available.")

    total_words_final = Statistics.get_word_count(final_story_body_text)
    end_time_total = time.time()
    total_generation_time_s = round(end_time_total - start_time_total)
    words_per_minute = (round(60 * (total_words_final / total_generation_time_s)) if total_generation_time_s > 0 else 0)

    logger.Log("--- STORY GENERATION COMPLETE ---", 0)
    logger.Log(f"Title: {story_title}", 0)
    logger.Log(f"Summary: {story_summary[:200]}...", 0)
    logger.Log(f"Tags: {story_tags}", 0)
    logger.Log(f"Total Chapters: {num_chapters}", 0)
    logger.Log(f"Final Word Count: {total_words_final}", 0)
    logger.Log(f"Total Generation Time: {total_generation_time_s}s (~{total_generation_time_s/60:.1f} min)", 0)
    logger.Log(f"Approximate WPM: {words_per_minute}", 0)

    stats_string = (
        f"# Work Statistics:\n"
        f"- **Title**: {story_title}\n"
        f"- **Summary**: {story_summary}\n"
        f"- **Tags**: {story_tags}\n"
        f"- **Total Chapters**: {num_chapters}\n"
        f"- **Final Word Count**: {total_words_final}\n"
        f"- **Generation Start Time**: {datetime.datetime.fromtimestamp(start_time_total).strftime('%Y-%m-%d %H:%M:%S')}\n"
        f"- **Total Generation Time**: {total_generation_time_s} seconds (~{total_generation_time_s/60:.1f} minutes)\n"
        f"- **Approximate Words Per Minute (Generation)**: {words_per_minute}\n\n"
        f"# User Prompt:\n```\n{original_user_prompt_for_log}\n```\n\n"
        f"# Key Configuration:\n"
        f"- **Seed**: {Config.SEED}\n"
        f"- **Primary Creative Models**:\n"
        f"    - Outline: {Config.INITIAL_OUTLINE_WRITER_MODEL}\n"
        f"    - Story Elements: {Config.MODEL_STORY_ELEMENTS_GENERATOR}\n"
        f"    - Scene Outliner: {Config.MODEL_SCENE_OUTLINER}\n"
        f"    - Scene Writer: {Config.MODEL_SCENE_NARRATIVE_GENERATOR}\n"
        f"    - Chapter Context Summarizer: {Config.MODEL_CHAPTER_CONTEXT_SUMMARIZER}\n"
        f"    - Chapter Assembly Refiner: {Config.MODEL_CHAPTER_ASSEMBLY_REFINER}\n"
        f"- **Revision & Utility Models**:\n"
        f"    - Chapter Revision: {Config.CHAPTER_REVISION_WRITER_MODEL}\n"
        f"    - Feedback (Critic): {Config.REVISION_MODEL}\n"
        f"    - Evaluation (Rating/JSON): {Config.EVAL_MODEL}\n"
        f"    - Metadata (Info): {Config.INFO_MODEL}\n"
        f"    - Scrubber: {Config.SCRUB_MODEL}\n"
        f"    - Checker (Chapter Count/Seg): {Config.CHECKER_MODEL}\n"
        f"    - Translator: {Config.TRANSLATOR_MODEL}\n"
        f"- **Debug Mode**: {Config.DEBUG} (Level: {Config.DEBUG_LEVEL})\n"
        f"- **Final Edit Pass**: {Config.ENABLE_FINAL_EDIT_PASS}\n"
        f"- **Scrubbing**: {'Disabled' if Config.SCRUB_NO_SCRUB else 'Enabled'}\n"
        f"- **Translation to**: {Config.TRANSLATE_LANGUAGE if Config.TRANSLATE_LANGUAGE else 'N/A'}\n"
        "(See Main.log in the log directory for full configuration details)"
    ).strip()

    final_output_markdown = (
        f"{stats_string}\n\n"
        f"---\n"
        f"**Note:** The full story elements and chapter-level plot outline are included at the end of this document.\n"
        f"---\n\n"
        f"# {story_title}\n\n"
        f"{final_story_body_text}\n\n"
        f"---\n"
        f"# Appendix: Story Foundation\n\n"
        f"## Base Story Context/Instructions from User Prompt:\n"
        f"```text\n{base_story_context_instructions if base_story_context_instructions.strip() else 'None extracted.'}\n```\n\n"
        f"## Generated Story Elements:\n"
        f"```markdown\n{story_elements_md}\n```\n\n"
        f"## Final Chapter-by-Chapter Plot Outline:\n"
        f"```markdown\n{chapter_level_plot_outline}\n```"
    ).strip()

    output_dir = "Stories"
    os.makedirs(output_dir, exist_ok=True)

    clean_title_for_filename = "".join(
        c if c.isalnum() or c in [" ", "_", "-"] else "" for c in story_title
    ).replace(" ", "_")
    if not clean_title_for_filename:
        clean_title_for_filename = f"Story_{datetime.datetime.now().strftime('%Y%m%d%H%M%S')}"

    base_filename = Config.OPTIONAL_OUTPUT_NAME if Config.OPTIONAL_OUTPUT_NAME else os.path.join(output_dir, clean_title_for_filename)

    md_filepath = f"{base_filename}.md"
    json_filepath = f"{base_filename}_data.json"

    logger.save_artifact(final_output_markdown, os.path.basename(md_filepath))

    story_data_for_json = {
        "title": story_title,
        "summary": story_summary,
        "tags": story_tags,
        "generation_timestamp_utc": datetime.datetime.utcnow().isoformat(),
        "original_user_prompt": original_user_prompt_for_log,
        "translated_user_prompt": user_prompt_text if Config.TRANSLATE_PROMPT_LANGUAGE else None,
        "base_story_context_instructions": base_story_context_instructions,
        "story_elements_markdown": story_elements_md,
        "chapter_level_plot_outline": chapter_level_plot_outline,
        "per_chapter_plot_segments_used": per_chapter_plot_outlines,
        "all_generated_scene_outlines": all_generated_scene_outlines_for_json_log,
        "num_chapters_generated": num_chapters,
        "config_settings_used": {
            key: getattr(Config, key) for key in dir(Config)
            if not key.startswith("__") and not callable(getattr(Config, key))
            and isinstance(getattr(Config, key), (str, int, float, bool, list, dict, type(None)))
        },
        "statistics": {
            "final_word_count": total_words_final,
            "total_generation_time_s": total_generation_time_s,
            "words_per_minute": words_per_minute,
        },
        "chapters_initial_assembly": generated_chapters_list,
        "chapters_globally_edited": globally_edited_chapters if Config.ENABLE_FINAL_EDIT_PASS else None,
        "chapters_scrubbed": scrubbed_chapters if not Config.SCRUB_NO_SCRUB else None,
        "chapters_final_output": final_chapters_for_output
    }
    try:
        if os.path.dirname(json_filepath):
            os.makedirs(os.path.dirname(json_filepath), exist_ok=True)
        with open(json_filepath, "w", encoding="utf-8") as f_json:
            json.dump(story_data_for_json, f_json, indent=2, ensure_ascii=False)
        logger.Log(f"Detailed story data JSON saved to: {json_filepath}", 1)
    except Exception as e:
        logger.Log(f"Error saving story data JSON to {json_filepath}: {e}", 7)

    logger.Log(f"Story generation process complete. Output: {md_filepath}", 0)
    logger.close()


if __name__ == "__main__":
    main()