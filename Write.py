# File: AIStoryWriter/write.py (Renamed from Write.py for convention)
# Purpose: Main orchestrator for the AI Story Writer application.

"""
AI Story Writer - Main Orchestration Script.

This script drives the entire story generation process, from taking a user's
initial prompt to producing a complete, multi-chapter narrative.
It initializes components, manages workflow (outline, chapters, scenes),
handles optional processing (editing, scrubbing, translation), extracts
metadata, and saves all outputs.
"""

import argparse
import time
import datetime
import os
import json
import sys
import re
from typing import List, Optional  # Removed unused Any

# Ensure the Writer package is discoverable.
try:
    import Writer.Config as Config
    import Writer.Interface.Wrapper as Wrapper
    import Writer.PrintUtils as PrintUtils
    import Writer.Chapter.ChapterDetector as ChapterDetector
    import Writer.Scrubber as Scrubber
    import Writer.Statistics as Statistics
    import Writer.OutlineGenerator as OutlineGenerator
    import Writer.Chapter.ChapterGenerator as ChapterGenerator
    import Writer.Chapter.ChapterContext as ChapterContext
    import Writer.StoryInfo as StoryInfo
    import Writer.NovelEditor as NovelEditor
    import Writer.Translator as Translator
except ImportError as e:
    current_dir = os.path.dirname(os.path.abspath(__file__))
    # If Write.py is in project root, Writer/ is a direct subdir.
    # If Write.py is in a subdir (e.g. scripts/), project_root is parent.
    project_root = current_dir  # Assume Write.py is in project root
    if "AIStoryWriter" in project_root.split(os.sep)[-1] and "Writer" not in os.listdir(
        project_root
    ):
        # This implies Write.py might be one level down, e.g. in a "scripts" folder.
        project_root = os.path.dirname(project_root)

    if project_root not in sys.path:
        sys.path.insert(0, project_root)
    try:
        import Writer.Config as Config
        import Writer.Interface.Wrapper as Wrapper
        import Writer.PrintUtils as PrintUtils
        import Writer.Chapter.ChapterDetector as ChapterDetector
        import Writer.Scrubber as Scrubber
        import Writer.Statistics as Statistics
        import Writer.OutlineGenerator as OutlineGenerator
        import Writer.Chapter.ChapterGenerator as ChapterGenerator
        import Writer.Chapter.ChapterContext as ChapterContext
        import Writer.StoryInfo as StoryInfo
        import Writer.NovelEditor as NovelEditor
        import Writer.Translator as Translator
    except ImportError:
        print(
            f"CRITICAL ERROR: Failed to import necessary Writer modules. Original error: {e}"
        )
        print(
            "Ensure AIStoryWriter modules are in PYTHONPATH or script is run from project root."
        )
        print(f"Current sys.path: {sys.path}")
        sys.exit(1)


def parse_arguments() -> argparse.Namespace:
    """Parses command-line arguments for the story generation script."""
    parser = argparse.ArgumentParser(
        description="AI Story Writer: Generates a multi-chapter narrative."
    )
    # Core Inputs/Outputs
    parser.add_argument(
        "-Prompt",
        required=True,
        help="Path to a text file containing the user's story prompt.",
    )
    parser.add_argument(
        "-Output",
        default="",
        type=str,
        help="Optional base filename for output (e.g., 'MyStory'). "
        "If empty, autogenerated from title.",
    )

    # Model Configuration
    parser.add_argument(
        "-InitialOutlineModel",
        default=Config.INITIAL_OUTLINE_WRITER_MODEL,
        type=str,
        help="Model for the main story outline.",
    )
    parser.add_argument(
        "-ModelStoryElementsGenerator",
        default=Config.MODEL_STORY_ELEMENTS_GENERATOR,
        type=str,
        help="Model for story elements (genre, theme, etc.).",
    )
    parser.add_argument(
        "-ModelSceneOutliner",
        default=Config.MODEL_SCENE_OUTLINER,
        type=str,
        help="Model for breaking chapters into scene outlines.",
    )
    parser.add_argument(
        "-ModelSceneNarrativeGenerator",
        default=Config.MODEL_SCENE_NARRATIVE_GENERATOR,
        type=str,
        help="Model for writing individual scene narratives.",
    )
    parser.add_argument(
        "-ModelChapterContextSummarizer",
        default=Config.MODEL_CHAPTER_CONTEXT_SUMMARIZER,
        type=str,
        help="Model for summarizing chapter/scene context.",
    )
    parser.add_argument(
        "-ModelChapterAssemblyRefiner",
        default=Config.MODEL_CHAPTER_ASSEMBLY_REFINER,
        type=str,
        help="Model for refining assembled scenes into a cohesive chapter.",
    )
    parser.add_argument(
        "-ChapterRevisionModel",
        default=Config.CHAPTER_REVISION_WRITER_MODEL,
        type=str,
        help="Model for revising chapters based on LLM feedback.",
    )
    parser.add_argument(
        "-RevisionModel",
        default=Config.REVISION_MODEL,
        type=str,
        help="Model for generating critique/feedback.",
    )
    parser.add_argument(
        "-EvalModel",
        default=Config.EVAL_MODEL,
        type=str,
        help="Model for evaluation tasks (e.g., ratings, JSON checks).",
    )
    parser.add_argument(
        "-InfoModel",
        default=Config.INFO_MODEL,
        type=str,
        help="Model for extracting story metadata (title, summary, tags).",
    )
    parser.add_argument(
        "-ScrubModel",
        default=Config.SCRUB_MODEL,
        type=str,
        help="Model for cleaning final text.",
    )
    parser.add_argument(
        "-CheckerModel",
        default=Config.CHECKER_MODEL,
        type=str,
        help="Model for simple validation/parsing aid (e.g., chapter count).",
    )
    parser.add_argument(
        "-TranslatorModel",
        default=Config.TRANSLATOR_MODEL,
        type=str,
        help="Model for translation tasks.",
    )

    # Generation Parameters
    parser.add_argument(
        "-Seed",
        default=Config.SEED,
        type=int,
        help="Seed for LLM generation (for reproducibility).",
    )
    parser.add_argument(
        "-Translate",
        default=Config.TRANSLATE_LANGUAGE,
        type=str,
        help="Target language for story translation (e.g., 'French'). Leave empty for no translation.",
    )
    parser.add_argument(
        "-TranslatePrompt",
        default=Config.TRANSLATE_PROMPT_LANGUAGE,
        type=str,
        help="Target language for user prompt translation (e.g., 'English' if prompt is non-English).",
    )

    # Revision Control
    parser.add_argument(
        "-OutlineMinRevisions",
        default=Config.OUTLINE_MIN_REVISIONS,
        type=int,
        help="Minimum revision cycles for the main outline.",
    )
    parser.add_argument(
        "-OutlineMaxRevisions",
        default=Config.OUTLINE_MAX_REVISIONS,
        type=int,
        help="Maximum revision cycles for the main outline.",
    )
    parser.add_argument(
        "-ChapterMinRevisions",
        default=Config.CHAPTER_MIN_REVISIONS,
        type=int,
        help="Minimum revision cycles for an assembled chapter.",
    )
    parser.add_argument(
        "-ChapterMaxRevisions",
        default=Config.CHAPTER_MAX_REVISIONS,
        type=int,
        help="Maximum revision cycles for an assembled chapter.",
    )
    parser.add_argument(
        "-NoChapterRevision",
        action="store_true",
        help="Disables feedback/revision loops for assembled chapters. Overrides Config default if present.",
    )

    # Feature Flags
    parser.add_argument(
        "-NoScrubChapters",
        action="store_true",
        help="Disables the final scrubbing pass on chapters. Overrides Config default if present.",
    )
    parser.add_argument(
        "-EnableFinalEditPass",
        action="store_true",
        help="Enables a global novel editing pass. Overrides Config default if present.",
    )

    # Debugging
    parser.add_argument(
        "-Debug",
        action="store_true",
        help="Enables verbose debugging output. Overrides Config default if present.",
    )
    parser.add_argument(
        "-DebugLevel",
        default=Config.DEBUG_LEVEL,
        type=int,
        help="Sets debug verbosity (0=off, 1=basic, 2=detailed: includes stream chunks).",
    )
    return parser.parse_args()


def apply_config_from_args(args: argparse.Namespace, logger: PrintUtils.Logger) -> None:
    """
    Applies parsed command-line arguments to the global Config module.
    This ensures that settings provided via CLI override the defaults in Config.py.
    """
    logger.Log("Applying command-line arguments to configuration...", 0)

    # Iterate over args and update Config if the arg was actually provided by the user
    # or if its default is different from Config (less common for most flags)
    for arg_name, arg_value in vars(args).items():
        config_attr_name = arg_name.upper()  # Assuming Config uses UPPERCASE names

        # Handle boolean flags (action="store_true") carefully
        # If a store_true flag is present in args, its value will be True.
        # If not present, its value will be False (argparse default for store_true if not specified)
        # We only want to override Config if the flag was explicitly used or has a different effective default.

        # Check if the argument was specified on the command line.
        # This is a bit tricky with argparse. One way is to see if the value is different
        # from the default defined in add_argument.
        # For store_true, if its default in add_argument was False, and args.Flag is True, it was specified.
        # If default was Config.FLAG, then args.Flag reflects that or the command line.

        # Simpler: just assign. Argparse defaults (if set from Config) will handle it.
        if hasattr(Config, config_attr_name):
            current_config_val = getattr(Config, config_attr_name)
            if current_config_val != arg_value:  # Log if there's a change
                logger.Log(
                    f"Config: '{config_attr_name}' changing from '{current_config_val}' to '{arg_value}' via CLI.",
                    0,
                )
            setattr(Config, config_attr_name, arg_value)
        elif arg_name in [
            "NoChapterRevision",
            "NoScrubChapters",
            "EnableFinalEditPass",
            "Debug",
        ]:
            # Handle boolean flags from argparse that might not directly map to UPPERCASE Config names
            # or have different default logic.
            # For example, if arg is NoChapterRevision (True if passed), set Config.CHAPTER_NO_REVISIONS = True
            if arg_name == "NoChapterRevision":
                Config.CHAPTER_NO_REVISIONS = arg_value
            if arg_name == "NoScrubChapters":
                Config.SCRUB_NO_SCRUB = arg_value
            if arg_name == "EnableFinalEditPass":
                Config.ENABLE_FINAL_EDIT_PASS = arg_value
            if arg_name == "Debug":
                Config.DEBUG = arg_value
            # For other flags, they directly map to uppercase, like SEED, TRANSLATE etc.

    Config.SCENE_GENERATION_PIPELINE = True  # This is central to the refactor
    logger.Log("Configuration updated from command-line arguments.", 0)


def load_user_prompt_file(
    prompt_filepath: str, logger: PrintUtils.Logger
) -> Optional[str]:
    """Loads content from the user's prompt file, with error handling."""
    logger.Log(f"Loading user prompt from: {prompt_filepath}", 1)
    if not os.path.exists(prompt_filepath):
        logger.Log(f"Error: Prompt file not found at '{prompt_filepath}'.", 7)
        return None
    try:
        with open(prompt_filepath, "r", encoding="utf-8") as f:
            prompt_text = f.read()
        if not prompt_text.strip():
            logger.Log(f"Warning: Prompt file '{prompt_filepath}' is empty.", 6)
            return ""
        logger.Log("User prompt loaded successfully.", 1)
        return prompt_text
    except IOError as e:  # More specific exception for file I/O issues
        logger.Log(f"Error reading prompt file '{prompt_filepath}': {e}", 7)
        return None
    except Exception as e:  # Catch-all for other unexpected errors
        logger.Log(f"Unexpected error reading prompt file '{prompt_filepath}': {e}", 7)
        return None


def split_overall_outline_into_chapter_plots(
    overall_chapter_level_outline: str,
    num_chapters: int,
    interface: Wrapper.Interface,
    logger: PrintUtils.Logger,
) -> List[str]:
    """
    Splits a comprehensive chapter-level outline into individual plot strings for each chapter.
    Uses regex first, then falls back to LLM-based segmentation if regex is inconclusive.
    """
    logger.Log(
        f"Segmenting overall outline into {num_chapters} chapter-specific plot outlines...",
        3,
    )

    # Regex to find "Chapter <number>[: title]" or "## Chapter <number>[: title]"
    # It captures content *after* the heading.
    # Using re.split is tricky because it removes the delimiter.
    # Instead, let's use re.findall or re.finditer with a pattern that captures chapter content.
    # This pattern looks for "Chapter X" and captures everything until the next "Chapter X" or end of string.
    pattern = re.compile(
        r"(?:Chapter\s*\d+\s*:?|\#{1,3}\s*Chapter\s*\d+\s*:?)[^\n]*\n(.*?)(?=\n(?:Chapter\s*\d+\s*:?|\#{1,3}\s*Chapter\s*\d+\s*:?)|\Z)",
        re.IGNORECASE | re.DOTALL,  # DOTALL allows . to match newlines
    )
    parsed_plots_via_find = [
        match.strip() for match in pattern.findall(overall_chapter_level_outline)
    ]

    if len(parsed_plots_via_find) == num_chapters:
        logger.Log(
            f"Successfully segmented outline into {num_chapters} chapter plots using regex findall.",
            4,
        )
        return parsed_plots_via_find

    logger.Log(
        f"Regex findall yielded {len(parsed_plots_via_find)} plots, expected {num_chapters}. Using LLM or broader regex split.",
        5,
    )

    # Fallback to previous regex split logic if findall didn't work as expected or for robustness
    chapter_segments = re.split(
        r"\n(?:Chapter\s*\d+\s*:?|\#{1,3}\s*Chapter\s*\d+\s*:?)[^\n]*\n",
        overall_chapter_level_outline,
        flags=re.IGNORECASE,
    )
    parsed_plots_via_split = [seg.strip() for seg in chapter_segments if seg.strip()]

    # Remove potential leading empty segment or "Introduction" if it's not counted as a chapter
    if parsed_plots_via_split and (
        not parsed_plots_via_split[0]
        or parsed_plots_via_split[0].lower().startswith(("introduction", "prologue"))
    ):
        if len(parsed_plots_via_split) - 1 == num_chapters:
            logger.Log("Adjusted regex split by removing initial segment.", 5)
            parsed_plots_via_split = parsed_plots_via_split[1:]

    if len(parsed_plots_via_split) == num_chapters:
        logger.Log(
            f"Successfully segmented outline into {num_chapters} chapter plots using regex split.",
            4,
        )
        return parsed_plots_via_split

    logger.Log(
        f"Regex split yielded {len(parsed_plots_via_split)} plots. Attempting LLM-based segmentation.",
        5,
    )

    prompt_text = (
        f"The following is a story outline that describes {num_chapters} chapters.\n"
        f"Please divide this outline into {num_chapters} distinct sections, where each section\n"
        f"corresponds to the plot summary or key events for one chapter.\n"
        f"Present your output as a JSON list of strings, where each string is the plot content for one chapter.\n"
        f"Ensure there are exactly {num_chapters} strings in the list. If the outline seems to have more or fewer logical chapter divisions than {num_chapters},\n"
        f"do your best to consolidate or expand to meet the {num_chapters} target, prioritizing the main plot points.\n\n"
        f"Original Outline:\n---\n{overall_chapter_level_outline}\n---\n\n"
        f"JSON List of Chapter Plot Strings (exactly {num_chapters} items):"
    )
    messages = [
        interface.build_system_query(
            "You are an AI assistant that accurately segments text into a specified number of chapter summaries and formats them as a JSON list."
        ),
        interface.build_user_query(prompt_text),
    ]
    try:
        _response_msgs, parsed_json_list = interface.safe_generate_json(
            logger, messages, Config.CHECKER_MODEL, required_attribs=[]
        )
        if isinstance(parsed_json_list, list) and all(
            isinstance(item, str) for item in parsed_json_list
        ):
            if len(parsed_json_list) == num_chapters:
                logger.Log(
                    f"LLM successfully segmented outline into {len(parsed_json_list)} chapter plots.",
                    4,
                )
                return parsed_json_list

            logger.Log(
                f"LLM segmentation returned {len(parsed_json_list)} plots, but {num_chapters} were expected. Adjusting list or using fallback.",
                6,
            )
            if len(parsed_json_list) > num_chapters:
                return parsed_json_list[:num_chapters]
            if len(parsed_json_list) < num_chapters and parsed_json_list:
                return parsed_json_list + [
                    "Plot segment for this chapter was not clearly delineated by LLM."
                ] * (num_chapters - len(parsed_json_list))
        else:
            logger.Log(
                f"LLM segmentation did not return a JSON list of strings. Type: {type(parsed_json_list)}. Using prior regex or crude split.",
                6,
            )
    except Exception as e:
        logger.Log(
            f"Error during LLM-based outline segmentation: {e}. Using prior regex or crude split.",
            6,
        )

    # Fallback to best regex result if LLM fails
    best_regex_plots = (
        parsed_plots_via_find
        if len(parsed_plots_via_find) > len(parsed_plots_via_split)
        else parsed_plots_via_split
    )
    if best_regex_plots and (
        len(best_regex_plots) >= num_chapters * 0.5
    ):  # If regex got something reasonable
        logger.Log(
            f"Falling back to best regex-parsed plots ({len(best_regex_plots)} found) due to LLM segmentation issues.",
            6,
        )
        if len(best_regex_plots) > num_chapters:
            return best_regex_plots[:num_chapters]
        return best_regex_plots + [
            "Plot segment missing or could not be parsed by regex."
        ] * (num_chapters - len(best_regex_plots))

    logger.Log(
        "All segmentation methods had issues. Performing a crude split. Chapter plot quality may be low.",
        7,
    )
    avg_len = (
        len(overall_chapter_level_outline) // num_chapters
        if num_chapters > 0
        else len(overall_chapter_level_outline)
    )
    if avg_len == 0 and num_chapters > 0:  # Avoid empty strings if possible
        return ["Error: Crude split resulted in empty segment."] * num_chapters
    return [
        overall_chapter_level_outline[i * avg_len : (i + 1) * avg_len].strip()
        or f"Segment {i+1} empty after crude split."
        for i in range(num_chapters)
    ]


def main() -> None:
    """Main function to orchestrate the story generation process."""
    args = parse_arguments()

    logger = PrintUtils.Logger(log_dir_base="Logs")
    logger.Log("AIStoryWriter Refactored - Initialization Started.", 0)
    apply_config_from_args(args, logger)

    start_time_total = time.time()

    models_to_load = list(
        set(
            [
                Config.INITIAL_OUTLINE_WRITER_MODEL,
                Config.MODEL_STORY_ELEMENTS_GENERATOR,
                Config.MODEL_SCENE_OUTLINER,
                Config.MODEL_SCENE_NARRATIVE_GENERATOR,
                Config.MODEL_CHAPTER_CONTEXT_SUMMARIZER,
                Config.MODEL_CHAPTER_ASSEMBLY_REFINER,
                Config.CHAPTER_REVISION_WRITER_MODEL,
                Config.REVISION_MODEL,
                Config.EVAL_MODEL,
                Config.INFO_MODEL,
                Config.SCRUB_MODEL,
                Config.CHECKER_MODEL,
                Config.TRANSLATOR_MODEL,
            ]
        )
    )

    try:
        interface = Wrapper.Interface(models_to_load=models_to_load)
        logger.Log("LLM Interface initialized with specified models.", 1)
    except Exception as e:
        logger.Log(f"CRITICAL: Failed to initialize LLM Interface: {e}. Aborting.", 7)
        logger.close()
        return

    user_prompt_text = load_user_prompt_file(args.Prompt, logger)
    if user_prompt_text is None:
        logger.Log("Exiting due to prompt loading error.", 7)
        logger.close()
        return

    original_user_prompt_for_log = user_prompt_text

    if Config.TRANSLATE_PROMPT_LANGUAGE:
        logger.Log(
            f"Translating user prompt to '{Config.TRANSLATE_PROMPT_LANGUAGE}' for LLM processing...",
            1,
        )
        user_prompt_text = Translator.translate_user_prompt(
            interface,
            logger,
            user_prompt_text,
            Config.TRANSLATE_PROMPT_LANGUAGE,
            # Assuming auto-detect or user_prompt_text's original lang is not passed here
        )
        if "Error:" in user_prompt_text:
            logger.Log(
                f"Prompt translation failed: {user_prompt_text}. Using original prompt.",
                6,
            )
            user_prompt_text = original_user_prompt_for_log

    logger.Log("Phase 1: Generating Story Outline...", 1)
    (
        full_printable_outline,
        story_elements_md,
        chapter_level_plot_outline,
        base_story_context_instructions,
    ) = OutlineGenerator.generate_outline(interface, logger, user_prompt_text)

    if "Error:" in chapter_level_plot_outline:
        logger.Log(
            f"Outline generation failed: {chapter_level_plot_outline}. Aborting.", 7
        )
        logger.save_artifact(full_printable_outline, "Errored_Outline.md")
        logger.close()
        return
    logger.save_artifact(story_elements_md, "1_StoryElements.md")
    logger.save_artifact(chapter_level_plot_outline, "2_ChapterLevelOutline_Raw.md")

    logger.Log("Phase 2: Determining Number of Chapters...", 1)
    num_chapters = ChapterDetector.llm_count_chapters(
        interface, logger, chapter_level_plot_outline
    )
    if num_chapters <= 0:
        logger.Log(
            f"Could not determine a valid number of chapters (detected: {num_chapters}). Aborting.",
            7,
        )
        logger.save_artifact(
            full_printable_outline, "3_FullPrintableOutline_PreChapterDetectionError.md"
        )
        logger.close()
        return
    logger.Log(f"Detected {num_chapters} chapters for the story.", 2)

    per_chapter_plot_outlines = split_overall_outline_into_chapter_plots(
        chapter_level_plot_outline, num_chapters, interface, logger
    )
    for i, plot in enumerate(per_chapter_plot_outlines):
        logger.save_artifact(plot, f"2a_Chapter_{i+1}_PlotSegment.txt")

    logger.Log(f"Phase 3: Generating {num_chapters} Chapter(s) Scene-by-Scene...", 1)
    generated_chapters_list: List[str] = []
    previous_chapter_context_summary: Optional[str] = None

    for i in range(num_chapters):
        current_chapter_num = i + 1
        logger.Log(
            f"--- Generating Chapter {current_chapter_num}/{num_chapters} ---", 2
        )

        current_chapter_specific_plot = per_chapter_plot_outlines[i]
        if not current_chapter_specific_plot.strip():
            logger.Log(
                f"Plot outline for Chapter {current_chapter_num} is empty. Attempting generation with broader context only.",
                6,
            )
            current_chapter_specific_plot = f"This is Chapter {current_chapter_num}. Refer to the overall story outline for guidance."

        generated_chapter_text = (
            ChapterGenerator.generate(  # Corrected function name to match module's member
                interface,
                logger,
                current_chapter_num,
                num_chapters,
                chapter_level_plot_outline,
                current_chapter_specific_plot,
                previous_chapter_context_summary,
                base_story_context_instructions,
            )
        )

        final_formatted_chapter_text = (
            f"## Chapter {current_chapter_num}\n\n{generated_chapter_text}"
        )
        generated_chapters_list.append(final_formatted_chapter_text)
        logger.save_artifact(
            final_formatted_chapter_text,
            f"3_Chapter_{current_chapter_num}_Generated.md",
        )

        if "Error:" in generated_chapter_text:
            logger.Log(
                f"Chapter {current_chapter_num} generation resulted in an error placeholder.",
                6,
            )
            previous_chapter_context_summary = (
                f"Context after Chapter {current_chapter_num} (which had errors): "
                "The story should proceed according to the overall outline."
            )
        elif current_chapter_num < num_chapters:
            logger.Log(
                f"Generating context summary for end of Chapter {current_chapter_num}...",
                3,
            )
            previous_chapter_context_summary = (
                ChapterContext.generate_previous_chapter_summary(
                    interface,
                    logger,
                    generated_chapter_text,
                    chapter_level_plot_outline,
                    current_chapter_num,
                )
            )
            if "Error:" in previous_chapter_context_summary:
                logger.Log(
                    f"Failed to generate context summary for Chapter {current_chapter_num}. Next chapter's context may be weak.",
                    6,
                )
                previous_chapter_context_summary = (
                    f"The story should proceed to Chapter {current_chapter_num + 1} as per the main outline. "
                    f"Chapter {current_chapter_num} involved: {current_chapter_specific_plot[:100]}..."
                )

    globally_edited_chapters = list(generated_chapters_list)
    if Config.ENABLE_FINAL_EDIT_PASS and num_chapters > 0:
        logger.Log("Phase 4: Performing Optional Global Novel Editing Pass...", 1)
        globally_edited_chapters = NovelEditor.edit_novel_globally(
            interface, logger, generated_chapters_list, chapter_level_plot_outline
        )
        for i, chap_text in enumerate(globally_edited_chapters):
            logger.save_artifact(chap_text, f"4_Chapter_{i+1}_GloballyEdited.md")
    else:
        logger.Log("Skipping optional global novel editing pass.", 1)

    scrubbed_chapters = list(globally_edited_chapters)
    if not Config.SCRUB_NO_SCRUB and num_chapters > 0:
        logger.Log("Phase 5: Scrubbing Final Novel Text...", 1)
        scrubbed_chapters = Scrubber.scrub_novel_chapters(
            interface, logger, globally_edited_chapters
        )
        for i, chap_text in enumerate(scrubbed_chapters):
            logger.save_artifact(chap_text, f"5_Chapter_{i+1}_Scrubbed.md")
    else:
        logger.Log("Skipping novel scrubbing pass.", 1)

    final_chapters_for_output = list(scrubbed_chapters)
    if Config.TRANSLATE_LANGUAGE and num_chapters > 0:
        logger.Log(f"Phase 6: Translating Novel to '{Config.TRANSLATE_LANGUAGE}'...", 1)
        final_chapters_for_output = Translator.translate_novel_chapters(
            interface,
            logger,
            scrubbed_chapters,
            Config.TRANSLATE_LANGUAGE,
            source_language_of_chapters="English",
        )
        for i, chap_text in enumerate(final_chapters_for_output):
            logger.save_artifact(
                chap_text, f"6_Chapter_{i+1}_Translated_{Config.TRANSLATE_LANGUAGE}.md"
            )
    else:
        logger.Log("Skipping novel translation.", 1)

    final_story_body_text = "\n\n\n".join(final_chapters_for_output)
    logger.save_artifact(final_story_body_text, "7_CompleteStory_Body.md")

    logger.Log("Phase 7: Generating Final Story Metadata (Title, Summary, Tags)...", 1)
    story_info_context_messages = [interface.build_user_query(full_printable_outline)]
    story_metadata = StoryInfo.get_story_info(
        interface, logger, story_info_context_messages
    )

    story_title = story_metadata.get(
        "Title", f"Untitled_Story_{datetime.datetime.now().strftime('%Y%m%d%H%M%S')}"
    )
    story_summary = story_metadata.get("Summary", "Summary not available.")
    story_tags = story_metadata.get("Tags", "No tags available.")

    total_words_final = Statistics.get_word_count(final_story_body_text)
    end_time_total = time.time()
    total_generation_time_s = round(end_time_total - start_time_total)
    words_per_minute = (
        round(60 * (total_words_final / total_generation_time_s))
        if total_generation_time_s > 0
        else 0
    )

    logger.Log(
        "--- STORY GENERATION COMPLETE ---", 0
    )  # Changed f-string to regular string
    logger.Log(f"Title: {story_title}", 0)
    logger.Log(f"Summary: {story_summary[:200]}...", 0)
    logger.Log(f"Tags: {story_tags}", 0)
    logger.Log(f"Total Chapters: {num_chapters}", 0)
    logger.Log(f"Final Word Count: {total_words_final}", 0)
    logger.Log(
        f"Total Generation Time: {total_generation_time_s}s (~{total_generation_time_s/60:.1f} min)",
        0,
    )
    logger.Log(f"Approximate WPM: {words_per_minute}", 0)

    stats_string = (
        f"# Work Statistics:\n"
        f"- **Title**: {story_title}\n"
        f"- **Summary**: {story_summary}\n"
        f"- **Tags**: {story_tags}\n"
        f"- **Total Chapters**: {num_chapters}\n"
        f"- **Final Word Count**: {total_words_final}\n"
        f"- **Generation Start Time**: {datetime.datetime.fromtimestamp(start_time_total).strftime('%Y-%m-%d %H:%M:%S')}\n"
        f"- **Total Generation Time**: {total_generation_time_s} seconds (~{total_generation_time_s/60:.1f} minutes)\n"
        f"- **Approximate Words Per Minute (Generation)**: {words_per_minute}\n\n"
        f"# User Prompt:\n```\n{original_user_prompt_for_log}\n```\n\n"
        f"# Key Configuration:\n"
        f"- **Seed**: {Config.SEED}\n"
        f"- **Primary Creative Models**:\n"
        f"    - Outline: {Config.INITIAL_OUTLINE_WRITER_MODEL}\n"
        f"    - Story Elements: {Config.MODEL_STORY_ELEMENTS_GENERATOR}\n"
        f"    - Scene Outliner: {Config.MODEL_SCENE_OUTLINER}\n"
        f"    - Scene Writer: {Config.MODEL_SCENE_NARRATIVE_GENERATOR}\n"
        f"    - Chapter Context Summarizer: {Config.MODEL_CHAPTER_CONTEXT_SUMMARIZER}\n"
        f"    - Chapter Assembly Refiner: {Config.MODEL_CHAPTER_ASSEMBLY_REFINER}\n"
        f"- **Revision & Utility Models**:\n"
        f"    - Chapter Revision: {Config.CHAPTER_REVISION_WRITER_MODEL}\n"
        f"    - Feedback (Critic): {Config.REVISION_MODEL}\n"
        f"    - Evaluation (Rating/JSON): {Config.EVAL_MODEL}\n"
        f"    - Metadata (Info): {Config.INFO_MODEL}\n"
        f"    - Scrubber: {Config.SCRUB_MODEL}\n"
        f"    - Checker (Chapter Count/Seg): {Config.CHECKER_MODEL}\n"
        f"    - Translator: {Config.TRANSLATOR_MODEL}\n"
        f"- **Debug Mode**: {Config.DEBUG} (Level: {Config.DEBUG_LEVEL})\n"
        f"- **Final Edit Pass**: {Config.ENABLE_FINAL_EDIT_PASS}\n"
        f"- **Scrubbing**: {'Disabled' if Config.SCRUB_NO_SCRUB else 'Enabled'}\n"
        f"- **Translation to**: {Config.TRANSLATE_LANGUAGE if Config.TRANSLATE_LANGUAGE else 'N/A'}\n"
        "(See Main.log in the log directory for full configuration details)"
    ).strip()

    final_output_markdown = (
        f"{stats_string}\n\n"
        f"---\n"
        f"**Note:** The full story elements and chapter-level plot outline are included at the end of this document.\n"
        f"---\n\n"
        f"# {story_title}\n\n"
        f"{final_story_body_text}\n\n"
        f"---\n"
        f"# Appendix: Story Foundation\n\n"
        f"## Base Story Context/Instructions from User Prompt:\n"
        f"```text\n{base_story_context_instructions if base_story_context_instructions.strip() else 'None extracted.'}\n```\n\n"
        f"## Generated Story Elements:\n"
        f"```markdown\n{story_elements_md}\n```\n\n"
        f"## Final Chapter-by-Chapter Plot Outline:\n"
        f"```markdown\n{chapter_level_plot_outline}\n```"
    ).strip()

    output_dir = "Stories"
    os.makedirs(output_dir, exist_ok=True)

    clean_title_for_filename = "".join(
        c if c.isalnum() or c in [" ", "_", "-"] else "" for c in story_title
    ).replace(" ", "_")
    if not clean_title_for_filename:
        clean_title_for_filename = (
            f"Story_{datetime.datetime.now().strftime('%Y%m%d%H%M%S')}"
        )

    base_filename = (
        Config.OPTIONAL_OUTPUT_NAME
        if Config.OPTIONAL_OUTPUT_NAME
        else os.path.join(output_dir, clean_title_for_filename)
    )

    md_filepath = f"{base_filename}.md"
    json_filepath = f"{base_filename}_data.json"

    md_subdirectory = None
    if os.path.isabs(base_filename) or os.path.dirname(base_filename):
        md_subdirectory = os.path.dirname(base_filename)
        if not md_subdirectory:
            md_subdirectory = None

    logger.save_artifact(
        final_output_markdown,
        os.path.basename(md_filepath),
        subdirectory=md_subdirectory,
    )

    story_data_for_json = {
        "title": story_title,
        "summary": story_summary,
        "tags": story_tags,
        "generation_timestamp_utc": datetime.datetime.utcnow().isoformat(),
        "original_user_prompt": original_user_prompt_for_log,
        "translated_user_prompt": (
            user_prompt_text if Config.TRANSLATE_PROMPT_LANGUAGE else None
        ),
        "base_story_context_instructions": base_story_context_instructions,
        "story_elements_markdown": story_elements_md,
        "chapter_level_plot_outline": chapter_level_plot_outline,
        "per_chapter_plot_segments_used": per_chapter_plot_outlines,
        "num_chapters_generated": num_chapters,
        "config_settings_used": {
            key: getattr(Config, key)
            for key in dir(Config)
            if not key.startswith("__")
            and not callable(getattr(Config, key))
            and isinstance(
                getattr(Config, key), (str, int, float, bool, list, dict, type(None))
            )
        },
        "statistics": {
            "final_word_count": total_words_final,
            "total_generation_time_s": total_generation_time_s,
            "words_per_minute": words_per_minute,
        },
        "chapters_initial_assembly": generated_chapters_list,
        "chapters_globally_edited": (
            globally_edited_chapters if Config.ENABLE_FINAL_EDIT_PASS else None
        ),
        "chapters_scrubbed": scrubbed_chapters if not Config.SCRUB_NO_SCRUB else None,
        "chapters_final_output": final_chapters_for_output,
    }
    try:
        with open(json_filepath, "w", encoding="utf-8") as f_json:
            json.dump(story_data_for_json, f_json, indent=2, ensure_ascii=False)
        logger.Log(f"Detailed story data JSON saved to: {json_filepath}", 1)
    except (
        IOError,
        TypeError,
        Exception,
    ) as e:  # Catch more specific errors for JSON dump
        logger.Log(f"Error saving story data JSON to {json_filepath}: {e}", 7)

    logger.Log(f"Story generation process complete. Output: {md_filepath}", 0)
    logger.close()


if __name__ == "__main__":
    main()
